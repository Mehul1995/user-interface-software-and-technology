<!DOCTYPE html>
<html>
	<head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<!-- Latest compiled and minified CSS -->
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
		
		<!-- Optional theme -->
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">
		
		<!-- Latest compiled and minified JavaScript -->
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
		
		<link rel="stylesheet" href="style.css" />
		
		<title>3D Visual Output</title>
		
	</head>
	<body>

		<p><a href="index.html">Back to table of contents</a></p>

		<img src="images/makerbot.jpg" class="img-responsive" alt="A Makerbot 3D printer printing a nested dodecahedron." />
		<small>A Makerbot 3D printer.</small>
		
		<h1>Physical Output</h1>

		<div class="lead">Andrew J. Ko</div>
		
		<p>Whereas the three-dimensional output we discussed in <a href="3D.html">the previous chapter</a> can create entirely new virtual worlds, or enhanced versions of our own world, it's equally important that software be able to interface with the <strong>physical world</strong>. In some sense, all output from computers is physical: the screens, holograms, and other light-based output from previous chapters are one class of output. The forms of output we discuss in this chapter just exploit <em>matter</em> instead of <em>light</em>.</p>
		
		<p>But matter matters. After all, the material world is the one are bodies live in, and so the information in the virtual world sometimes needs to be part of the physical world. In the seminal paper, "Tangible Bits: Towards Seamless Interfaces between People, Bits and Atoms", Hiroshi Ishii and rygg Ullmer argued (<a href="TODO">2006</a>):</p>
		
		<blockquote>
			We live between two realms: our physical environment and cyberspace. Despite our dual citizenship, the absence of seamless couplings between these parallel existences leaves a great divide between the worlds of bits and atoms. At the present, we are torn between these parallel but disjoint spaces... Streams of bits leak out of cyberspace through a myriad of rectangular screens into the physical world as photon beams. However, the interactions between people and cyberspace are now largely confined to traditional GUI (Graphical User Interface)-based boxes sitting on desktops or laptops. The interactions with these GUIs are separated from the ordinary physical environment within which we live and interact. Although we have developed various skills and work practices for processing information through haptic interactions with physical objects (e.g., scribbling messages on Post-It&trade; notes and spatially manipulating them on a wall) as well as peripheral senses (e.g., being aware of a change in weather through ambient light), most of these practices are neglected in current HCI design because of the lack of diversity of input/output media, and too much bias towards graphical output at the expense of input from the real world.
		</blockquote>
		
		<p>This basic idea, that the massive rift between our physical and digital worlds should be bridged by a diversity of new input and output media, dovetailed Weiser's vision of ubiquitous computing, but emphasizing our embodied experiences with physical objects.</p>
		
		<p>The result of these ideas was an explosion of research to create more physical, tangible input and output. In this chapter, we'll focus on output, discussing printing, haptics, and other forms of actuation from computers.</p>

		<h2>Printing</h2>

		<p>Most people who've interacted with computers have used a printer at some point in their life to turn bits into atoms. The basic principle is simple: take a digital document and create a facsimile with paper and some kind of mark, such as spraying ink (inkjets), burning the paper (laser printers), or one of a variety of other approaches.</p>

		TODO Write ticker-tape section, include a photo.

		TODO Write printer paragraph, include a photo.
		
		<p>All of these approaches have focused on 2-dimensional output, primarily because the media we've made easy to create on computers has been 2-dimensional. However, as the plastics industry evolved, 3D plastic extruders reshaped manufacturing. We began to be surrounded by objects of all shapes and sizes made of plastic, each printed from a mold. While this has created a literal tons of non-biodegradable waste, it also created the urge to democratize plastics manufacturing. This led to the first personal 3D printers (TODO), allowing people to create digital documents that represented 3D forms, and then print them using new forms of plastic extrusion.</p>

		<img src="images/TODO.jpg" class="img-responsive" alt="TODO" />
		<small>The first 3D printer</small>

		<p>While the basic idea of 3D printing is now well established, and the market for 3D printers is expanding, researchers have gone well beyond the original premise. Much of this exploration has been in exploring materials other than plastic. One example of this is an approach to printing <em>interactive electromechanical objects with wound in place coils</em> (<a href="https://doi.org/10.1145/2984511.2984523">Peng et al. 2016</a>). These objects, made of copper wire, and structural plastic elements, allows for the printing of objects like actuated arms of toys, electric motors, and electronic displays:</p>

		<p class="embed-responsive embed-responsive-16by9">
	        <iframe width="560" height="315" src="https://www.youtube.com/embed/5MEYe-z9GKo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
			<center>Printing electromagnetic objects.</center>
		</p>

		<p>Another project explored printing with wool and wool blend yarn to create soft felt objects rather than just rigid plastic objects (<a href="https://doi.org/10.1145/2556288.2557338">Hudson 2014</a>). Techniques like this and the one above simultaneously innovate in printing techniques, but also in exploring the possibilities of new media for bridging the digital and physical world.</p>
		
		<p>Of course, new media also pose new challenges. For example, trying to create 3D models for printing requires understanding the limitation of printing methods. This lack of understanding can lead to failed prints, which can be frustrating and expensive.	Some researchers have explored "patching" 3D objects, calculating additional parts that must be printed and mounted onto an existing failed print to create the desired shape (<a href="https://doi.org/10.1145/2807442.2807467">Teubrich et al. 2015</a>). Other research has investigated new software tools for extending, repairing, or modifying everyday objects by modeling those objects and streamlining the creation of attachment objects (<a href="https://doi.org/10.1145/2807442.2807498">Chen et al. 2015</a>):</p>

		<p class="embed-responsive embed-responsive-16by9">
	        <iframe width="560" height="315" src="https://www.youtube.com/embed/obui6I2dzxk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
			<center>Designing and printing attachment objects.</center>
		</p>
		
		<p>These techniques, while not advancing <em>how</em> objects are printed, innovate in how we author objects to print, much like research innovations in word processing software from the 1980's and 1990's.</p>

		<h2>Flexible interfaces</h2>
		
		<p>One of the defining characteristics of screens is their rigidity. Their fixed shape and size constrain everything else about an experience. Consider playful Nintendo's Labo, for example, which takes the Switch screen and wraps a wild array of cardboard around it to create new experiences:</p>
		
		TODO Labo video
		
		<p>Notice how everything is physical except for the screen.</p>
		
		<p>Researchers have worked hard to make interactive objects themselves more physical by making them flexible and bendable. For example, One technique takes paper, plastics, and fabrics, and makes it easy to create programmable shape-changing behaviors with those materials (<a href="https://doi.org/10.1145/2984511.2984520">Ou et al. 2016</a>):</p>

		<p class="embed-responsive embed-responsive-16by9">
        	<iframe width="560" height="315" src="https://www.youtube.com/embed/b1vrvDUr1Ds" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
			<center>Programmable, shape-changing materials.</center>
		</p>

		<p>Other projects have created <em>stretchable</em> user interfaces with sensing capabilities and visual output, allowing for conventional experiences in unconventional places (<a href="https://doi.org/10.1145/2984511.2984521">Wessley et al. 2016</a>):</p>
		
		<p class="embed-responsive embed-responsive-16by9">
      	  <iframe width="560" height="315" src="https://www.youtube.com/embed/gPVdvxfeE50" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
			<center>Stretchable interfaces.</center>
		</p>
		
		<p>Some research has even explored foldable interactive objects by using thin-film printed electronics (<a href="https://doi.org/10.1145/2807442.2807494">Olberding et al. 2015</a>):</p>
		
		<p class="embed-responsive embed-responsive-16by9">
	        <iframe width="560" height="315" src="https://www.youtube.com/embed/yQjhe0Ravf0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
			<center>Foldeable interfaces.</center>
		</p>

		<p>This research innovates in both the industrial forms that interfaces take, while offering new possibilities for how they are manipulated physically.</p>
        
		<h2>Haptic feedback</h2>
        
        <p>Whereas flexible interfaces change the <em>structural</em> properties of the interface forms, others have focused on offering physical, tangible feedback. This is called <strong>haptic</strong> feedback, because it leverages people's perception of touch and sense of where their body is in space (known as proprioception).</p>
        
        <p>Haptic feedback varies in its goals. For instance, some haptic feedback operates at a low level of human performance, such as this idea, which recreates the physical sensation of writing on paper with a pencil, ball-point pen or marker pen, but with a stylus (<a href="https://doi.org/10.1145/2984511.2984550">Cho et al. 2016</a>:</p>
        
		<p class="embed-responsive embed-responsive-16by9">
	        <iframe width="560" height="315" src="https://www.youtube.com/embed/RNn0_rkFXkw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
			<center>Simulated writing feedback.</center>
		</p>

		<p>Other haptic feedback aims to provide feedback about user interface behavior using physical force. For example, one project used electrical muscle stimulation to steer the user's wrist while plotting charts, filling in forms, and other tasks, to prevent errors (<a href="https://doi.org/10.1145/2984511.2984530">Lopes et al. 2016</a>). Another used airflow to provide feedback without contact (<a href="https://doi.org/10.1145/2984511.2984583">Lee and Lee 2016</a>):</p>
		
		<p class="embed-responsive embed-responsive-16by9">
        	<iframe width="560" height="315" src="https://www.youtube.com/embed/QdSK_K3Spcw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
			<center>Feedback with airflow.</center>
		</p>

		<p>Many projects have used haptics to communicate detailed shape information, helping to bring tactile information to visual virtual worlds. Some have used ultrasound to project specific points of feedback onto hands in midair (<a href="https://doi.org/10.1145/2501988.2502018">Carter et al. 2013</a>). Others used electrovibration, integrated with touch input, enabling the design interfaces that allow users to feel virtual elements (<a href="https://doi.org/10.1145/1866029.1866074">Bau et al. 2010</a>). Some projects have used physical forms to provide shape information, such as this gel-based surface imposed on a multi-touch sensor allowing for freely morphed arbitrary shapes (<a href="https://doi.org/10.1145/2807442.2807487">Miruchna et al. 2015</a>:</p>
		
		<p class="embed-responsive embed-responsive-16by9">
	        <iframe width="560" height="315" src="https://www.youtube.com/embed/o8W6qbwPhwU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
			<center>Gel-based multi-touch tactile feedback.</center>
		</p>

		<p>Some work leverages <strong>visuo-haptic illusions</strong> to successfully trick a user's mind into feeling something virtual. For example, one work displayed a high resolution visual form with tactile feedback from a low-resolution grid of actuated pins that move up and down, giving a sense of high-resolution tactile feedback (<a href="https://doi.org/10.1145/3173574.3173724">Abtahi et al 2018</a>). Some projects have created a sense of virtual motion by varying waves of actuator motion left or right (<a href="https://doi.org/10.1145/2380296.2380300">Kaye 2012</a>). In anticipation of virtual reality simulations of combat, some have even created perceptions of being physically hit by tapping the skin gently while thrusting a user's arm backwards using electrical muscle stimulation (<a href="https://doi.org/10.1145/2807442.2807443">Lopes et al. 2015</a>):</p>
		
		<p class="embed-responsive embed-responsive-16by9">
	        <iframe width="560" height="315" src="https://www.youtube.com/embed/CNEZguz1NEU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
			<center>Simulating impact.</center>
		</p>

		<p>All of these approaches to haptic feedback bridge the digital and physical worlds by letting information from digital world to reach our tactile senses.</p>

		<hr/>
		
		<p>While this exploration of media for bridging bits and atoms has been quite broad, it is not yet deep. Many of these techniques are only just barely feasible, and we still know little about what we might do with these techniques, how useful or valued these applications might be, or what it would take to manufacture and maintain the hardware they require. Nevertheless, it's clear that the tangible bits that Ishii and Ullmer envisioned in 2006 are not only possible, but rich, under-explored, and potentially transformative.</p>
		
		<center><p class="lead"><a href="help.html">Next chapter: Help</a></p></center>

		<h2>Further reading</h2>

		<p>Parastoo Abtahi, and Sean Follmer. 2018. <a href="https://doi.org/10.1145/3173574.3173724">Visuo-haptic Illusions for Improving the Perceived Performance of Shape Displays</a>. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, NY, USA.</p>

		<p>Olivier Bau, Ivan Poupyrev, Ali Israr, and Chris Harrison. 2010. <a href="https://doi.org/10.1145/1866029.1866074">TeslaTouch: electrovibration for touch surfaces</a>. In Proceedings of the 23nd annual ACM symposium on User interface software and technology (UIST '10). ACM, New York, NY, USA, 283-292.</p>
		
		<p>Tom Carter, Sue Ann Seah, Benjamin Long, Bruce Drinkwater, and Sriram Subramanian. 2013. <a href="https://doi.org/10.1145/2501988.2502018">UltraHaptics: multi-point mid-air haptic feedback for touch surfaces</a>. In Proceedings of the 26th annual ACM symposium on User interface software and technology (UIST '13). ACM, New York, NY, USA, 505-514.</p>

		<p>Xiang 'Anthony' Chen, Stelian Coros, Jennifer Mankoff, and Scott E. Hudson. 2015. <a href="https://doi.org/10.1145/2807442.2807498">Encore: 3D Printed Augmentation of Everyday Objects with Printed-Over, Affixed and Interlocked Attachments</a>. In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology (UIST '15). ACM, New York, NY, USA, 73-82.</p>

		<p>Artem Dementyev, Hsin-Liu (Cindy) Kao, Inrak Choi, Deborah Ajilo, Maggie Xu, Joseph A. Paradiso, Chris Schmandt, and Sean Follmer. 2016. <a href="https://doi.org/10.1145/2984511.2984531">Rovables: Miniature On-Body Robots as Mobile Wearables</a>. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA, 111-120.</p>

		<p>Scott E. Hudson. 2014. <a href="https://doi.org/10.1145/2556288.2557338">Printing teddy bears: a technique for 3D printing of soft interactive objects</a>. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '14). ACM, New York, NY, USA, 459-468.</p>

		<p>Hiroshi Ishii and Brygg Ullmer. (1997). <a href="TODO">Tangible bits: Towards seamless interfaces between people, bit, and atoms</a>. Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI ’97). Atlanta, Georgia (March 22-27, 1997). New York: ACM Press, pp. 234-241.</p>

		<p>Jaeyeon Lee and Geehyuk Lee. 2016. <a href="https://doi.org/10.1145/2984511.2984583">Designing a Non-contact Wearable Tactile Display Using Airflows</a>. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA, 183-194.</p>

		<p>Mathieu Le Goc, Lawrence H. Kim, Ali Parsaei, Jean-Daniel Fekete, Pierre Dragicevic, and Sean Follmer. 2016. <a href="https://doi.org/10.1145/2984511.2984547">Zooids: Building Blocks for Swarm User Interfaces</a>. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA, 97-109.</p>

		<p>Joseph 'Jofish' Kaye. 2012. <a href="https://doi.org/10.1145/2380296.2380300">Sawtooth planar waves for haptic feedback</a>. In Adjunct proceedings of the 25th annual ACM symposium on User interface software and technology (UIST Adjunct Proceedings '12). ACM, New York, NY, USA, 5-6.</p>

		<p>Pedro Lopes, Alexandra Ion, and Patrick Baudisch. 2015. <a href="https://doi.org/10.1145/2807442.2807443">Impacto: Simulating Physical Impact by Combining Tactile Stimulation with Electrical Muscle Stimulation</a>. In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology (UIST '15). ACM, New York, NY, USA, 11-19.</p>

		<p>Pedro Lopes, Doăa Yüksel, François Guimbretière, and Patrick Baudisch. 2016. <a href="https://doi.org/10.1145/2984511.2984530">Muscle-plotter: An Interactive System based on Electrical Muscle Stimulation that Produces Spatial Output</a>. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA, 207-217.</p>

		<p>Viktor Miruchna, Robert Walter, David Lindlbauer, Maren Lehmann, Regine von Klitzing, and Jörg Müller. 2015. <a href="https://doi.org/10.1145/2807442.2807487">GelTouch: Localized Tactile Feedback Through Thin, Programmable Gel</a>. In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology (UIST '15). ACM, New York, NY, USA, 3-10.</p>

		<p>Ken Nakagaki, Artem Dementyev, Sean Follmer, Joseph A. Paradiso, and Hiroshi Ishii. 2016. <a href="https://doi.org/10.1145/2984511.2984587">ChainFORM: A Linear Integrated Modular Hardware System for Shape Changing Interfaces. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA, 87-96.</p>

		<p>Huaishu Peng, François Guimbretière, James McCann, and Scott Hudson. 2016. <a href="https://doi.org/10.1145/2984511.2984523">A 3D Printer for Interactive Electromagnetic Devices</a>. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA, 553-562.</p>

		<p>Oliver S. Schneider, Ali Israr, and Karon E. MacLean. 2015. <a href="https://doi.org/10.1145/2807442.2807470">Tactile Animation by Direct Manipulation of Grid Displays</a>. In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology (UIST '15). ACM, New York, NY, USA, 21-30.</p>

		<p>Alexander Teibrich, Stefanie Mueller, François Guimbretière, Robert Kovacs, Stefan Neubert, and Patrick Baudisch. 2015. <a href="https://doi.org/10.1145/2807442.2807467">Patching Physical Objects</a>. In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology (UIST '15). ACM, New York, NY, USA, 83-91.</p>

		<p>Simon Olberding, Sergio Soto Ortega, Klaus Hildebrandt, and Jürgen Steimle. 2015. <a href="https://doi.org/10.1145/2807442.2807494">Foldio: Digital Fabrication of Interactive and Shape-Changing Objects With Foldable Printed Electronics</a>. In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology (UIST '15). ACM, New York, NY, USA, 223-232.</p>

		<p>Jifei Ou, Mélina Skouras, Nikolaos Vlavianos, Felix Heibeck, Chin-Yi Cheng, Jannik Peters, and Hiroshi Ishii. 2016. <a href="https://doi.org/10.1145/2984511.2984520">aeroMorph - Heat-sealing Inflatable Shape-change Materials for Interaction Design</a>. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA, 121-132.</p>

		<p>Michael Wessely, Theophanis Tsandilas, and Wendy E. Mackay. 2016. <a href="https://doi.org/10.1145/2984511.2984521">Stretchis: Fabricating Highly Stretchable User Interfaces</a>. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA, 697-704.</p>

	</body>
	
</html>

