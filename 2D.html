<!DOCTYPE html>
<html>
	<head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<!-- Latest compiled and minified CSS -->
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
		
		<!-- Optional theme -->
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">
		
		<!-- Latest compiled and minified JavaScript -->
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
		
		<link rel="stylesheet" href="style.css" />
		
		<title>2D Visual Output</title>
		
	</head>
	<body>

		<p><a href="index.html">Back to table of contents</a></p>

		<img src="images/pong.png" class="img-responsive" alt="A screenshot of the original Pong video game with two paddles, a ball, and scores." />
		<small>Pong, one of the earliest arcade video games.</small>
		
		<h1>2D Output</h1>

		<div class="lead">Andrew J. Ko</div>

		<p>It's easy to forget that computers didn't always have screens. The original format for computer output was actually printed, not rendered, and as with even modern printers, printing was slow. It wasn't until Ivan Sutherland integrated a CRT screen with a computer that screens enabled interactive, immediate feedback experiences.</p>
		
		<p>But screens alone were not enough. There was an entire set of new concepts that needed to be invented to make use of screens, ranging from graphics, typography, images, visualization, and animated versions of all of these media. And researchers continue to innovate in these spaces, including in screen technology itself. In this chapter, we'll review screen technology, and then discuss these media.</p>

		<p>Screens</p>

		* CRT, LCD, LED		
        * Low-energy wireless, batteryless display <a href="https://doi.org/10.1145/2984511.2984513">Grosse-Puppendahl et al. 2016</a>
        * Bendable 3D parallax display: <a href="https://doi.org/10.1145/2984511.2984524">Gotsch et al. 2016</a>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/mGJe0AdszJg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        * A small near-eye display with input capabilities. (<a href="https://doi.org/10.1145/2642918.2647361">Lyons et al. 2014</a>)
        <iframe width="560" height="315" src="https://www.youtube.com/embed/0-LZOil6UE8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        * Transparent displays with control to remove barriers while preserving privacy (<a href="https://doi.org/10.1145/2642918.2647350">Lindlbauer et al. 2014</a>)
        * Moveable interactive displays with image projection (<a href="https://doi.org/10.1145/1095034.1095045">Lee et al. 2005</a>)
        * Foldable interactive displays with image projection (<a href="https://doi.org/10.1145/1449715.1449763">Lee et al. 2008</a>)
        * Multi-user handheld projector interaction <a href="https://doi.org/10.1145/1294211.1294220">Cao et al. 2007</a>	


		<h2>Graphics</h2>

Origin
Typically 0,0 in top left
Comes from text handling and raster scan
Java 2D allows customization
Different from conventional axes
Coordinates of pixels:
Center of pixel?
Corner of pixel?
Matters for lines

Drawing Objects:
Graphics, graphics2D java APIs: http://docs.oracle.com/javase/7/docs/api/ 
P1 and P2 or P1 and W/H?
void  graphics.drawRect (int x, int y, int width, int height)Draws the outline of the specified rectangle. (also fillRect)
Inclusive or exclusive?
Which pixels are turned on for DrawRectangle (2,2, 8,8)? 
Suppose you draw another rectangle next to it? 
Suppose draw filled and outline rectangle with the same coordinates?
What about for ellipse?

Double buffering
Save an extra picture offscreen 
Smoother animations 
Save hidden parts of windows 
= “Backing store” 
Use two buffers for special effects, faster refresh 
“Save-under” for pop-ups 

Color models		
RGB -- Additive color primaries 
CMY --  Cyan, Magenta, Yellow 
complements of red, green, blue; subtractive primaries 
colors are specified that are removed from white light, instead of added to black (no light) as in RGB      
YIQ  -- used in color TVs in US (NTSC) 
Y is luminance, what is shown on black and white TVs 
I and Q encode chromaticity  
HSV -- Hue, Saturation and Value (brightness) or HSL (Luminance)
user oriented, intuitive appear of artist's hint, shade, tone 
simple algorithm in text to convert, but not a linear mapping 
Interpolating between colors can be done using different models, with different resulting intermediate colors
		
		Pictures created externally
“Bitmaps”, “Pixmaps”
Various encodings
bmp, pict, gif, tiff, jpeg, png, …
Issues:
Origin for when used as a cursor
Encodings for transparency
Windows cursors and gif files
Java uses alpha compositing
Java drawImage


		<h2>Typography</h2>
		
		Font provides description of the shape of a collection of chars
Shapes are called “glyphs”
Plus information e.g. about how to advance after drawing a glyph
And aggregate info for the whole collection

Fonts
Typically specified by:
A family or typeface
e.g., courier, helvetica, times roman
A size (normally in “points”)
A style
e.g., plain, italic, bold, bold & italic
other possibles (from mac): underline, outline, shadow

An odd and archaic unit of measurement
72.27 points per inch
Origin: 72 per French inch (!)
Postscript rounded to 72/inch
Most have followed
Early Macintosh: point==pixel (1/75th)

baseline
ascent
descent
Glyphs are drawn both above and below baseline
Distance below: “decent” of glyph
Distance above: “ascent” of glyph

Kerning: overlapping of characters: VA, ff, V.
Stroke: Element of a character that would have originally been created with a single pen stroke
Em: Equal to the font's point size. So an "Em-dash" in a 18 point font is 18points wide: (option-shift-underline on Mac)
En: Half font's point size. "En-dash" is 9 points wide in 18 point font: (Mac: option-underline)
DASHES – DASHES—DASHES

Conventional ASCII
One byte per character
Various special characters in lower and upper part of fonts
Depends on OS, font, etc.
Unicode: http://www.unicode.org
16 bits per character
All the world’s languages
Java uses Unicode
		
		<h2>Images</h2>

		<h2>Data</h2>
		
		Optional Protovis: A Graphical Toolkit for Visualization. Michael Bostock, Jeffrey Heer. IEEE TVCG 2009. pdf
		Other Jeff Heer stuff
		
		


	
	
		<h2>Animation</h2>
		
		<p>
			Some of the first efforts to create animated computer graphics were 40's, 50's, and 60's, just as digital computers were being invented (Sito 2013).
			As computers become more ubiquitous, researchers began to explore digital animation in film, which eventually led to the ACM SIGGRAPH conference on computer graphics.
			This academic community, joining forces with the rising interest in computer graphics, generated decades of discoveries creating ever more realistic animations, and eventually led to our modern industry of 3D animated films.
		</p>
		
		<p>
			As graphical user interfaces emerged in the 1980's, animation of interfaces became a significant topic of research.
			An early work investigated foundations of animation that might be brought from film animation, including principles of <strong>solidity</strong>, <strong>exaggeration</strong>, and <strong>reinforcement</strong>, which were long used to give life to static images (<a href="https://doi.org/10.1145/168642.168647">Chang and Ungar 1993</a>).
			These principles were tied to specific time-based visual ideas such as arcs, follow-through, slow in/slow out, anticipation, arrivals and departures, and motion blur, all of which are now ubiquitous in things like presentation software and modern graphical user interfaces.
			Just as these types of motion are used in movies to convey information about action, they are now used in user interfaces to convey information, as in this animation in OS X that simulates a head shaking "no":
		</p>

		<p class="embed-responsive embed-responsive-16by9">
			<iframe width="560" height="315" src="https://www.youtube.com/embed/W_WRCMGs1f0?controls=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
			<center>A shaking animation, conveying an incorrect password.</center>
		</p>

		<p>
			While this basic idea of animating interfaces was straightforward, finding ways to seamlessly implement animation into interfaces was not. 
			Having parts of interfaces move required careful management of the position of interface elements over time, and these were incompatible with the notion of view hierarchies determining element positions at all times.
			Some of the earliest ideas involved defining <strong>constraints</strong>, and letting those constraints determining position over time (<a href="https://doi.org/10.1145/237091.237109">Myers et al. 1996</a>): for example, a developer might say that an element should be at position A at time t, then at position B at time t+1, and then let the user interface toolkit decide precisely where to render the element between those two times.
			This same idea could be used to animate any visual property of an element, such as its color, transparency, size, and so on.
			These same ideas eventually led to more sophisticated animations of direct manipulation interfaces (<a href="https://doi.org/10.1145/215585.215628">Thomas and Calder 1995</a>), of icons (<a href="https://doi.org/10.1145/1978942.1979232">Harrison et al. 2011</a>), of typography engine (<a href="https://doi.org/10.1145/571985.571997">Lee et al. 2002</a>).
			These ideas coalesced into well-defined transition abstractions that made it easier to express a range of "emotions" through transitions, such as urgency, delay, and confidence (<a href="https://doi.org/10.1145/168642.168648">Hudson and Stasko 1993</a>).
		</p>

	    * Typography
            * Describes a way of structuring dynamic, interactive typography (<a href="https://doi.org/10.1145/320719.322594">Lewis and Weyers</a>)
            * Kinetic typography engine: a toolkit for generating animated typography, small set of abstractions, large expressivity (<a href="https://doi.org/10.1145/571985.571997">Lee et al. 2002</a>)

		Kinetic typography example.
		
		<p>
			All of these research ideas are now ubiquitous in toolkits like Apple's <a href="https://developer.apple.com/library/content/documentation/Cocoa/Conceptual/CoreAnimation_guide/Introduction/Introduction.html">Core Animation</a>, which make it easy to express animation states without having to manage low-level details of user interface rendering.
		</p>
		
		
			
		
		
		
		
		
		
		
		<center><p class="lead"><a href="3D.html">Next chapter: 3D output</a></p></center>

		<h2>Further reading</h2>

		<p>Xiang Cao, Clifton Forlines, and Ravin Balakrishnan. 2007. <a href="https://doi.org/10.1145/1294211.1294220">Multi-user interaction using handheld projectors</a>. In Proceedings of the 20th annual ACM symposium on User interface software and technology (UIST '07). ACM, New York, NY, USA, 43-52.</p>
		
		<p>Bay-Wei Chang and David Ungar. 1993. <a href="https://doi.org/10.1145/168642.168647">Animation: from cartoons to the user interface</a>. In Proceedings of the 6th annual ACM symposium on User interface software and technology (UIST '93). ACM, New York, NY, USA, 45-55.</p>

		<p>Chris Harrison, Gary Hsieh, Karl D.D. Willis, Jodi Forlizzi, and Scott E. Hudson. 2011. <a href="https://doi.org/10.1145/1978942.1979232">Kineticons: using iconographic motion in graphical user interface design</a>. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). ACM, New York, NY, USA, 1999-2008.</p>

		<p>Tobias Grosse-Puppendahl, Steve Hodges, Nicholas Chen, John Helmes, Stuart Taylor, James Scott, Josh Fromm, and David Sweeney. 2016. <p>Exploring the Design Space for Energy-Harvesting Situated Displays</p>. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA, 41-48.</p>

		<p>Daniel Gotsch, Xujing Zhang, Juan Pablo Carrascal, and Roel Vertegaal. 2016. <a href="https://doi.org/10.1145/2984511.2984524">HoloFlex: A Flexible Light-Field Smartphone with a Microlens Array and a P-OLED Touchscreen</a>. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST '16). ACM, New York, NY, USA, 69-79.</p>
			
		<p>Scott E. Hudson and John T. Stasko. 1993. <a href="https://doi.org/10.1145/168642.168648">Animation support in a user interface toolkit: flexible, robust, and reusable abstractions</a>. In Proceedings of the 6th annual ACM symposium on User interface software and technology (UIST '93). ACM, New York, NY, USA, 57-67.</p>

		<p>Johnny C. Lee, Jodi Forlizzi, and Scott E. Hudson. 2002. <a href="https://doi.org/10.1145/571985.571997">The kinetic typography engine: an extensible system for animating expressive text</a>. In Proceedings of the 15th annual ACM symposium on User interface software and technology (UIST '02). ACM, New York, NY, USA, 81-90.</p>

		<p>Johnny C. Lee, Jodi Forlizzi, and Scott E. Hudson. 2002. <a href="https://doi.org/10.1145/571985.571997">The kinetic typography engine: an extensible system for animating expressive text</a>. In Proceedings of the 15th annual ACM symposium on User interface software and technology (UIST '02). ACM, New York, NY, USA, 81-90.</p>

		<p>Johnny C. Lee, Scott E. Hudson, Jay W. Summet, and Paul H. Dietz. 2005. <a href="http://dx.doi.org/10.1145/1095034.1095045">Moveable interactive projected displays using projector based tracking</a>. In Proceedings of the 18th annual ACM symposium on User interface software and technology (UIST '05). ACM, New York, NY, USA, 63-72.</p>
			
		<p>Johnny C. Lee, Scott E. Hudson, and Edward Tse. 2008. <a href="https://doi.org/10.1145/1449715.1449763">Foldable interactive displays</a>. In Proceedings of the 21st annual ACM symposium on User interface software and technology (UIST '08). ACM, New York, NY, USA, 287-290.</p>

		<p>Jason E. Lewis and Alex Weyers. 1999. <a href="http://dx.doi.org/10.1145/320719.322594">ActiveText: a method for creating dynamic and interactive texts</a>. In Proceedings of the 12th annual ACM symposium on User interface software and technology (UIST '99). ACM, New York, NY, USA, 131-140.</p>

		<p>David Lindlbauer, Toru Aoki, Robert Walter, Yuji Uema, Anita Höchtl, Michael Haller, Masahiko Inami, and Jörg Müller. 2014. <a href="https://doi.org/10.1145/2642918.2647350">Tracs: transparency-control for see-through displays</a>. In Proceedings of the 27th annual ACM symposium on User interface software and technology (UIST '14). ACM, New York, NY, USA, 657-661.</p>

		<p>Kent Lyons, Seung Wook Kim, Shigeyuki Seko, David Nguyen, Audrey Desjardins, Mélodie Vidal, David Dobbelstein, and Jeremy Rubin. 2014. <a href="https://doi.org/10.1145/2642918.2647361">Loupe: a handheld near-eye display</a>. In Proceedings of the 27th annual ACM symposium on User interface software and technology (UIST '14). ACM, New York, NY, USA, 351-354.</p>

		<p>Brad A. Myers, Robert C. Miller, Rich McDaniel, and Alan Ferrency. 1996. <a href="http://dx.doi.org/10.1145/237091.237109">Easily adding animations to interfaces using constraints</a>. In Proceedings of the 9th annual ACM symposium on User interface software and technology (UIST '96). ACM, New York, NY, USA, 119-128.</p>

		<p>Sito, T. (2013). Moving innovation: a history of computer animation. MIT Press.</p>

		<p>Bruce H. Thomas and Paul Calder. 1995. <a href="http://dx.doi.org/10.1145/215585.215628">Animating direct manipulation interfaces</a>. In Proceedings of the 8th annual ACM symposium on User interface and software technology (UIST '95). ACM, New York, NY, USA, 3-12.</p>

	</body>
	
</html>

